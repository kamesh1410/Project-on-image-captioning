{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "id": "yNOF-6JPA_4x",
        "outputId": "4535e2c8-e29f-4771-dc0b-8bd1221adaab"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/gradio/interface.py:403: UserWarning: The `allow_flagging` parameter in `Interface` is deprecated.Use `flagging_mode` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://73717efd1ee6841049.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://73717efd1ee6841049.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
        "import torch\n",
        "from PIL import Image\n",
        "import gradio as gr\n",
        "\n",
        "model_name = \"Salesforce/blip-image-captioning-base\"\n",
        "processor = BlipProcessor.from_pretrained(model_name)\n",
        "model = BlipForConditionalGeneration.from_pretrained(model_name).to(\"cuda\")\n",
        "\n",
        "def generate_caption(image):\n",
        "    inputs = processor(images=image, return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = model.generate(**inputs, max_new_tokens=50)\n",
        "\n",
        "    caption = processor.decode(output[0], skip_special_tokens=True)\n",
        "    return caption\n",
        "\n",
        "custom_css = \"\"\"\n",
        "#title {color: #ffffff; text-align: center; font-size: 30px; font-weight: bold;}\n",
        "#desc {color: #ffffff; text-align: center; font-size: 18px;}\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "iface = gr.Interface(\n",
        "    fn=generate_caption,\n",
        "    inputs=\"image\",\n",
        "    outputs=gr.Textbox(label=\"Generated Caption\"),\n",
        "    title=\"ðŸ“¸ Image Captioning with BLIP\",\n",
        "    description=\"Upload an image, and the model will generate a caption.\",\n",
        "    allow_flagging=\"never\",\n",
        "    live=True,\n",
        "    css=custom_css,\n",
        ")\n",
        "\n",
        "iface.launch(share=True)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
